{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Lsa5MKfYYo-f"
      },
      "outputs": [],
      "source": [
        "# CNN model from scratch \n",
        "\n",
        "# Using pytorch only for data loading \n",
        "# import keras\n",
        "import numpy as np\n",
        "import tensorflow.keras as tk\n",
        "from scipy import signal\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tk.datasets.cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "tDoWDUlteKQi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "def preprocess_data(x, y, size):\n",
        "   \n",
        "    x = x.astype(\"float32\") / 255.0\n",
        "    # encode output which is a number in range [0,9] into a vector of size 10\n",
        "    # e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "    y = np_utils.to_categorical(y)\n",
        "    y = y.reshape(y.shape[0], 10, 1)\n",
        "    return x[:size], y[:size]\n",
        "\n",
        "\n",
        "x_train , y_train = preprocess_data(x_train , y_train, 10000)\n",
        "x_test, y_test = preprocess_data(x_test, y_test, 2000)\n",
        "\n",
        "data_batches = []\n",
        "for i in range(0, len(x_train), batch_size):\n",
        "    images_batch = x_train[i:i+batch_size]\n",
        "    labels_batch = y_train[i:i+batch_size]\n",
        "    data_batches.append((np.array(images_batch), np.array(labels_batch)))"
      ],
      "metadata": {
        "id": "UoU6qhKieQJe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_batches[0])"
      ],
      "metadata": {
        "id": "j7le3cxlhWVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Layers "
      ],
      "metadata": {
        "id": "X0xWbM2NiP_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        pass\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        pass"
      ],
      "metadata": {
        "id": "zuBtjA8Bh_3P"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ---------------------- Pooling Layer -------------------------\n",
        "#=================================================================\n",
        "class maxPool(Layer):\n",
        "  def __init__(self,input_shape,kernel, stride):\n",
        "    input_depth, input_height, input_width = input_shape\n",
        "    self.depth = input_depth\n",
        "    self.height = input_height\n",
        "    self.width = input_width\n",
        "    self.kernel_size = kernel\n",
        "    self.stride = stride\n",
        "    self.out_h = int(1 + (self.height - self.kernel_size) / self.stride)\n",
        "    self.out_w = int(1 + (self.width - self.kernel_size) / self.stride)\n",
        "    # self.batch_size = batch_size\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = np.zeros((self.depth, self.out_h, self.out_w))\n",
        "    self.input = input\n",
        "    # for n in range(self.batch_size):\n",
        "    for c in range(self.depth):\n",
        "          for hi in range(self.out_h):\n",
        "              for wi in range(self.out_w):\n",
        "                  out[c, hi, wi] = np.max(input[c, hi * self.stride : hi * self.stride + self.kernel_size,\n",
        "                                                wi * self.stride : wi * self.stride + self.kernel_size ]) \n",
        "    return out\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "    # dout = np.random.randn( self.depth, self.height, self.width) # output gradients\n",
        "    \n",
        "    dx = np.zeros_like(self.input)\n",
        "    # for n in range(self.batch_size):\n",
        "    for c in range(self.depth):\n",
        "          for i in range(self.out_h):\n",
        "              for j in range(self.out_w):\n",
        "                start_i = i*self.stride\n",
        "                start_j = j*self.stride\n",
        "                end_i = start_i + self.kernel_size\n",
        "                end_j = start_j + self.kernel_size\n",
        "                max_idx = np.argmax(self.input[c,start_i:end_i, start_j:end_j])\n",
        "                (idx_i,idx_j) = np.unravel_index(max_idx,(self.kernel_size,self.kernel_size))\n",
        "                dx[c,start_i+idx_i,start_j+idx_j] += output_gradient[c,i,j]\n",
        "    return dx "
      ],
      "metadata": {
        "id": "egRDuaWTiXNE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q-1jcxhRt4Hl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolutional(Layer):\n",
        "    def __init__(self, input_shape, kernel_size, depth):\n",
        "        input_depth, input_height, input_width = input_shape\n",
        "        self.depth = depth\n",
        "        self.input_shape = input_shape\n",
        "        self.input_depth = input_depth\n",
        "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
        "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
        "        self.kernels = np.random.randn(*self.kernels_shape)\n",
        "        self.biases = np.random.randn(*self.output_shape)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = np.copy(self.biases)\n",
        "        for i in range(self.depth):\n",
        "            for j in range(self.input_depth):\n",
        "                self.output[i] += signal.correlate2d(self.input[j], self.kernels[i, j], \"valid\")\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        kernels_gradient = np.zeros(self.kernels_shape)\n",
        "        input_gradient = np.zeros(self.input_shape)\n",
        "\n",
        "        for i in range(self.depth):\n",
        "            for j in range(self.input_depth):\n",
        "                # print(\"===+\")\n",
        "                kernels_gradient[i, j] = signal.correlate2d(self.input[j], output_gradient[i], \"valid\")\n",
        "                # print(\"===-\")\n",
        "                input_gradient[j] += signal.convolve2d(output_gradient[i], self.kernels[i, j], \"full\")\n",
        "\n",
        "        self.kernels -= learning_rate * kernels_gradient\n",
        "        self.biases -= learning_rate * output_gradient\n",
        "        return input_gradient\n",
        "\n",
        "# class Convolutional:                                        # convolution layer using 3x3 filters\n",
        "\n",
        "#     def __init__(self, num_filters=16, stride=1, size=3, activation=None):\n",
        "#         # self.name = name\n",
        "#         self.filters = np.random.randn(num_filters, 3, 3) * 0.1\n",
        "#         self.stride = stride\n",
        "#         self.size = size\n",
        "#         self.activation = activation\n",
        "#         self.last_input = None\n",
        "#         # self.leakyReLU = np.vectorize(leakyReLU)\n",
        "#         # self.leakyReLU_derivative = np.vectorize(leakyReLU_derivative)\n",
        "\n",
        "#     def forward(self, image):\n",
        "#         self.last_input = image                             # keep track of last input for later backward propagation\n",
        "\n",
        "#         input_dimension = image.shape[1]                                                # input dimension\n",
        "#         output_dimension = int((input_dimension - self.size) / self.stride) + 1         # output dimension\n",
        "\n",
        "#         out = np.zeros((self.filters.shape[0], output_dimension, output_dimension))     # create the matrix to hold the\n",
        "#                                                                                         # values of the convolution\n",
        "\n",
        "#         for f in range(self.filters.shape[0]):              # convolve each filter over the image,\n",
        "#             tmp_y = out_y = 0                               # moving it vertically first and then horizontally\n",
        "#             while tmp_y + self.size <= input_dimension:\n",
        "#                 tmp_x = out_x = 0\n",
        "#                 while tmp_x + self.size <= input_dimension:\n",
        "#                     patch = image[:, tmp_y:tmp_y + self.size, tmp_x:tmp_x + self.size]\n",
        "#                     out[f, out_y, out_x] += np.sum(self.filters[f] * patch)\n",
        "#                     tmp_x += self.stride\n",
        "#                     out_x += 1\n",
        "#                 tmp_y += self.stride\n",
        "#                 out_y += 1\n",
        "#         # if self.activation == 'relu':                       # apply ReLU activation function\n",
        "#         #     self.leakyReLU(out)\n",
        "#         return out\n",
        "\n",
        "#     def backward(self, din, learn_rate=0.005):\n",
        "#         input_dimension = self.last_input.shape[1]          # input dimension\n",
        "\n",
        "#         # if self.activation == 'relu':                       # back propagate through ReLU\n",
        "#         #    self.leakyReLU_derivative(din)\n",
        "\n",
        "#         dout = np.zeros(self.last_input.shape)              # loss gradient of the input to the convolution operation\n",
        "#         dfilt = np.zeros(self.filters.shape)                # loss gradient of filter\n",
        "\n",
        "#         for f in range(self.filters.shape[0]):              # loop through all filters\n",
        "#             tmp_y = out_y = 0\n",
        "#             while tmp_y + self.size <= input_dimension:\n",
        "#                 tmp_x = out_x = 0\n",
        "#                 while tmp_x + self.size <= input_dimension:\n",
        "#                     patch = self.last_input[:, tmp_y:tmp_y + self.size, tmp_x:tmp_x + self.size]\n",
        "#                     dfilt[f] += np.sum(din[f, out_y, out_x] * patch, axis=0)\n",
        "#                     dout[:, tmp_y:tmp_y + self.size, tmp_x:tmp_x + self.size] += din[f, out_y, out_x] * self.filters[f]\n",
        "#                     tmp_x += self.stride\n",
        "#                     out_x += 1\n",
        "#                 tmp_y += self.stride\n",
        "#                 out_y += 1\n",
        "#         self.filters -= learn_rate * dfilt                  # update filters using SGD\n",
        "#         return dout     "
      ],
      "metadata": {
        "id": "5FoJiWvLSgf3"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# Define a 2D convolution layer\n",
        "class Conv2D(Layer):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        \n",
        "        # Initialize the weights and biases\n",
        "        self.weights = np.random.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "        self.bias = np.zeros((out_channels,))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        in_channels, height, width = x.shape\n",
        "        out_height = int((height + 2*self.padding - self.kernel_size) / self.stride + 1)\n",
        "        out_width = int((width + 2*self.padding - self.kernel_size) / self.stride + 1)\n",
        "        \n",
        "        # Add padding to the input\n",
        "        padded_x = np.pad(x, ( (0,0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
        "        \n",
        "        # Initialize the output\n",
        "        out = np.zeros(( self.out_channels, out_height, out_width))\n",
        "        \n",
        "        # Perform the convolution operation\n",
        "        \n",
        "        for c in range(self.out_channels):\n",
        "            for i in range(out_height):\n",
        "                for j in range(out_width):\n",
        "                    out[ c, i, j] = np.sum(self.weights[c] * padded_x[ :, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size]) + self.bias[c]\n",
        "                    \n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_out,learning_rate):\n",
        "        batch_size, in_channels, height, width = self.input.shape\n",
        "        grad_x = np.zeros_like(self.input)\n",
        "        grad_weights = np.zeros_like(self.weights)\n",
        "        grad_bias = np.zeros_like(self.bias)\n",
        "        \n",
        "        # Add padding to the input\n",
        "        padded_x = np.pad(self.input, ( (0,0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
        "        \n",
        "        # Compute the gradients\n",
        "        \n",
        "        for c in range(self.out_channels):\n",
        "            for i in range(grad_out.shape[2]):\n",
        "                for j in range(grad_out.shape[3]):\n",
        "                    grad_x[ :, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size] += grad_out[ c, i, j] * self.weights[c]\n",
        "                    grad_weights[c] += grad_out[ c, i, j] * padded_x[ :, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size]\n",
        "                    grad_bias[c] += grad_out[ c, i, j]\n",
        "                    \n",
        "        # Remove padding from the gradients\n",
        "        grad_x = grad_x[ :, self.padding:-self.padding, self.padding:-self.padding]\n",
        "        self.bias -= learning_rate * grad_bias\n",
        "        self.weights -= learning_rate*grad_weights\n",
        "        \n",
        "        return grad_x\n"
      ],
      "metadata": {
        "id": "HHh5GMMcvlVt"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Layer "
      ],
      "metadata": {
        "id": "DOJd64kGt-4X"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Reshape(Layer):\n",
        "#     def __init__(self, input_shape, output_shape, batch_size):\n",
        "#         input_depth, input_height, input_width = input_shape\n",
        "#         output_depth = output_shape[0]\n",
        "#         self.input_shape = input_shape\n",
        "#         self.output_shape = output_shape\n",
        "#         self.batch_size = batch_size\n",
        "#         self.outshape = (batch_size,output_depth)\n",
        "#         self.inshape = (batch_size,)\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         output = np.zeros(self.outshape)\n",
        "#         for n in range(self.batch_size):\n",
        "#           output[n]+= np.reshape(input, self.output_shape)\n",
        "#         return output\n",
        "\n",
        "#     def backward(self, output_gradient, learning_rate):\n",
        "#         in_grad = np.zeros(self.inshape)\n",
        "#         for n in range(self.batch_size):\n",
        "#           in_grad[n]+= np.reshape(output_gradient, self.input_shape)\n",
        "#         return in_grad\n",
        "\n"
      ],
      "metadata": {
        "id": "YG2l-ElNUWZ7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully Connected Layer "
      ],
      "metadata": {
        "id": "iDXn5GvVuFh8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Reshape(Layer):\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        self.input_shape = input_shape\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, input):\n",
        "        return np.reshape(input, self.output_shape)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        return np.reshape(output_gradient, self.input_shape)"
      ],
      "metadata": {
        "id": "0KUXZ_iAyJdm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU(Layer):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def forward(self, x):\n",
        "      self.input = x\n",
        "      return np.maximum(0, x)\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "      return output_gradient * (self.input > 0)"
      ],
      "metadata": {
        "id": "JLiEcjJTycZ0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnected(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights_shape = (output_size, input_size)\n",
        "        self.bias_shape = (output_size, 1)\n",
        "        weights = np.random.randn(* self.weights_shape)\n",
        "        std = np.std(weights)\n",
        "        self.weights =weights/std\n",
        "        bias = np.random.randn(* self.bias_shape)\n",
        "        std = np.std(bias)\n",
        "        self.bias = bias/std\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(self.weights, self.input) + self.bias\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
        "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.bias -= learning_rate * output_gradient\n",
        "        return input_gradient"
      ],
      "metadata": {
        "id": "V6iEJyeozLNq"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Functions \n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / np.size(y_true)\n",
        "\n",
        "# def binary_cross_entropy(y_true, y_pred):\n",
        "#     return np.mean(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# def binary_cross_entropy_prime(y_true, y_pred):\n",
        "#     return ((1 - y_true) / (1 - y_pred) - y_true / y_pred) / np.size(y_true)"
      ],
      "metadata": {
        "id": "rL-Wmemzz4Fy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model "
      ],
      "metadata": {
        "id": "zWPlpX2_12a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Net:\n",
        "  def __init__(self):\n",
        "    self.conv1 = Convolutional((3,32,32),3,32)  # Kernel size = 3x3  in: 3 out 32\n",
        "    self.pool1 = maxPool((32,30,30),2,1)     # Kernel size = 2x2\n",
        "    self.conv2 = Convolutional((32,29,29),5,64) # Kernel size = 3x3  in:  out 64\n",
        "    self.pool2 = maxPool((64,25,25),2,1)     # Kernel size = 2x2\n",
        "    self.conv3 = Convolutional((64,24,24),3,64)\n",
        "    self.reshape = Reshape((64,22,22),(64*22*22,1))\n",
        "    self.fc1 = FullyConnected(64*22*22,64)\n",
        "    self.fc2 = FullyConnected(64,10)\n",
        "    self.relu1 = ReLU()  \n",
        "    self.relu2 = ReLU()  \n",
        "    self.relu3 = ReLU()  \n",
        "    self.relu4 = ReLU()  \n",
        "\n",
        "  def forward(self,input):\n",
        "    x = self.conv1.forward(input)\n",
        "    x = self.relu1.forward(x)\n",
        "    x = self.pool1.forward(x)\n",
        "    x = self.conv2.forward(x)\n",
        "    x = self.relu2.forward(x)\n",
        "    x = self.pool2.forward(x)\n",
        "    x = self.conv3.forward(x)\n",
        "    x = self.relu3.forward(x)\n",
        "    x = self.reshape.forward(x)\n",
        "    x = self.fc1.forward(x)\n",
        "    x = self.relu4.forward(x)\n",
        "    x = self.fc2.forward(x)\n",
        "    return x\n",
        "\n",
        "  def backward(self, out_grad , learning_rate):\n",
        "      x = self.fc2.backward(out_grad , learning_rate)\n",
        "      x = self.relu4.backward(x , learning_rate)\n",
        "      x = self.relu4.backward(x , learning_rate)\n",
        "      x = self.fc1.backward(x , learning_rate)\n",
        "      x = self.reshape.backward(x , learning_rate)\n",
        "      x = self.relu3.backward(x , learning_rate)\n",
        "      x = self.conv3.backward(x , learning_rate)\n",
        "      x = self.pool2.backward(x , learning_rate)\n",
        "      x = self.relu2.backward(x , learning_rate)\n",
        "      x = self.conv2.backward(x , learning_rate)\n",
        "      x = self.pool1.backward(x , learning_rate)\n",
        "      x = self.relu1.backward(x , learning_rate)\n",
        "      x = self.conv1.backward(x , learning_rate)\n",
        "     \n",
        "      return x\n",
        "\n",
        "     \n",
        "     \n",
        "    \n",
        "def Accuracy(model , X , Y):\n",
        "  correct_pred = 0\n",
        "  for x, y in zip(X, Y):\n",
        "    output = model.forward(x)\n",
        "    pred = np.argmax(output)\n",
        "    trueVal = np.argmax(y)\n",
        "    if trueVal == pred : \n",
        "      correct_pred+=1\n",
        "  acc = float(correct_pred)/float(len(X))\n",
        "  # print(\"Accuracy : \",acc)\n",
        "  return acc\n",
        "\n",
        "class CNNModel:\n",
        "  def __init__(self,trainX,trainY,valX, valY,epoch, learning_rate):\n",
        "    self.train_X = trainX\n",
        "    self.train_Y = trainY\n",
        "    self.val_X = valX\n",
        "    self.val_Y = valY\n",
        "    self.best = None\n",
        "    self.Epoch = epoch\n",
        "    self.learning_rate = learning_rate\n",
        "    self.models = []\n",
        "    self.AccT = []\n",
        "    self.AccV = []\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "    model = Net()\n",
        "    Models = []\n",
        "    AccT =[]\n",
        "    AccV = []\n",
        "    Epoch = []\n",
        "\n",
        "    for e in range(self.Epoch):\n",
        "       error = 0 \n",
        "       i=0\n",
        "       for x in self.train_X:\n",
        "        #  print(x)\n",
        "         y= self.train_Y[i]\n",
        "         i+=1\n",
        "         output = model.forward(x)\n",
        "        #  print(output.shape)\n",
        "         error+= mse(y, output)\n",
        "         print(\"=====================================\")\n",
        "         print(output)\n",
        "         print(y)\n",
        "         grad = mse_prime(y, output)\n",
        "         grad = model.backward(grad, self.learning_rate)\n",
        "       error /= len(self.train_X)\n",
        "       print(f\"{e + 1}/{self.Epoch}, error={error}\")\n",
        "       accT = Accuracy(model, self.train_X,self.train_Y)\n",
        "       accV = Accuracy(model , self.val_X,self.val_Y)\n",
        "       AccT.append(accT)\n",
        "       AccV.append(accV)\n",
        "       print(f'Accuracy of the network on the 10000 test images: {AccT} %')\n",
        "       print(f'Accuracy of the network on the train images: {AccV} %')\n",
        "       M = model\n",
        "       Models.append(M)\n",
        "       Epoch.append(e+1)\n",
        "    self.models = Models\n",
        "    self.AccT = AccT\n",
        "    self.AccV = AccV\n",
        "    print(\"Training Done!\")\n",
        "\n",
        "M = CNNModel(x_train , y_train, x_test, y_test, 5 , 0.005)\n",
        "M.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "id": "88Cmr0Ca19lD",
        "outputId": "c5e87907-6c94-40a1-eee1-421fd6987405"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Output of Reshape :  (30976, 1)\n",
            "Shape of Output of FC1 :  (64, 1)\n",
            "Shape of Output of FC2 :  (10, 1)\n",
            "=====================================\n",
            "[[ 958905.69178429]\n",
            " [-764103.62866035]\n",
            " [-715950.0312968 ]\n",
            " [-378893.2879596 ]\n",
            " [ 823565.52679697]\n",
            " [ 498195.67681581]\n",
            " [-105623.30512001]\n",
            " [ 194363.68465366]\n",
            " [1622740.84396926]\n",
            " [-444464.55665676]]\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "----------------\n",
            "----------------\n",
            "----------------\n",
            "----------------\n",
            "----------------\n",
            "----------------\n",
            "----------------\n",
            "----------------\n",
            "(32, 30, 30)\n",
            "-3---------------\n",
            "(32, 30, 30)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-7506ddc70dd0>\u001b[0m in \u001b[0;36m<cell line: 136>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-94-7506ddc70dd0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m          \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m          \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m          \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m        \u001b[0merror\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{e + 1}/{self.Epoch}, error={error}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-7506ddc70dd0>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, learning_rate)\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-3---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-96b701fc3458>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, output_gradient, learning_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# print(\"===+\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mkernels_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# print(\"===-\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0minput_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/signal/_signaltools.py\u001b[0m in \u001b[0;36mcorrelate2d\u001b[0;34m(in1, in2, mode, boundary, fillvalue)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'correlate2d inputs must both be 2-D arrays'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0mswapped_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inputs_swap_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mswapped_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/signal/_signaltools.py\u001b[0m in \u001b[0;36m_inputs_swap_needed\u001b[0;34m(mode, shape1, shape2, axes)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mok1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mok2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         raise ValueError(\"For 'valid' mode, one must be at least \"\n\u001b[0m\u001b[1;32m     85\u001b[0m                          \"as large as the other in every dimension\")\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: For 'valid' mode, one must be at least as large as the other in every dimension"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dK9vGgCApwcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oTC6CM-k9Xxz"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}